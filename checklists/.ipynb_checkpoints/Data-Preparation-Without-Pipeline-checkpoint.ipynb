{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "Dieses Notebook, dient lediglich zu Entwicklung von Vorverarbeitungsstrategien. Daher wird auf jedes Feature grob eingegangen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliiotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelList=['symboling','normalizedLosses','make','fuelType','aspiration','numOfDoors','bodyStyle','driveWheels','engineLocation',\n",
    "           'wheelBase','length','width','height','curbWeight','engineType','numOfCylinders','engineSize','fuelSystem','bore',\n",
    "           'stroke','compressionRatio','horsepower','peakRpm','cityMpg','highwayMpg','price']\n",
    "df = pd.read_csv('../data/data_car-CopyForEDA.csv',delimiter=',',encoding='utf-8', names=labelList)\n",
    "df = df.replace(\"?\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## symboling\n",
    "laut First-Touch kein Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## price\n",
    "NAs werden duch den Druchschnittswert der Marke ausgewählt\n",
    "Der Datentyp wird in int gewandelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#df.price.isna().any()# > sind noch nas\n",
    "df[['price']]=df[['price']].astype('float64')\n",
    "for i in range(0, len(df.price),1):\n",
    "    if(str(df.price[i]) == \"nan\"):\n",
    "        nanmake = (df.make[i])\n",
    "        subSetNanMake=df[df['make'] == nanmake]\n",
    "        subSetNanMake = subSetNanMake.price.dropna()\n",
    "        medianPerMake = subSetNanMake.median(axis = 0, skipna = True)\n",
    "        df.price[i] = medianPerMake\n",
    "#df.price.isna().any() => keine Nas Mehr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numOfDoors\n",
    "nas werden durch den Modus ersetzt der entsprechenden Wagenklasse(bodyStyle). ich geh davon aus dass eine wagenklasse meist die gleiche Türenanzhal hat => ich setzt den Modus dazu rein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two' 'four' nan]\n"
     ]
    }
   ],
   "source": [
    "print(df.numOfDoors.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#df.numOfDoors.isna().any() #=> noch nas\n",
    "for i in range(0, len(df.numOfDoors),1):\n",
    "    if(str(df.numOfDoors[i]) == \"nan\"):\n",
    "        nanBodyStyle = (df.bodyStyle[i])\n",
    "        subSetNanBody=df[df['bodyStyle'] == nanBodyStyle]\n",
    "        subSetNanBody = subSetNanBody.numOfDoors.dropna()\n",
    "        modusNumOfDoors = subSetNanBody.mode().iloc[0]\n",
    "        #print(modusNumOfDoors)\n",
    "        df.numOfDoors[i] = modusNumOfDoors\n",
    "#df.numOfDoors.isna().any() # => keine Nas Mehr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der nachfolgede Teil zu numOfDoors ist aufgekommen, da im OHE ein außergewöhnlicher wert erschienen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two' 'four']\n"
     ]
    }
   ],
   "source": [
    "print(df.numOfDoors.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bore & Stroke & horse power & Peakrpm\n",
    "Das sind die Parameter, die den Hubraum(engine-Size) beschreiben. Nach ewig langer recherche errechne ich aber auch  bei Datensätzen bei welchen ich sowohl bore, stroke, horsepower & PRPM als auch engine habnciht den richtigen Hubrubraum. Somit geh ich anders vor.\n",
    "    1) finde Nonvalues in den bereichen (glück = bei Stroke&bore als auch bei HP&PRPM sind es jeweils die gleichen Datensätze)\n",
    "    2) wähle von nonvalue die Enigine size\n",
    "    3) finde die nächst kleinere Engine size\n",
    "    4) impute von den nächst kleineren die bore & Storke values dem leeren Feld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bore.isna().any()\n",
    "df.stroke.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 61, '2.91', '3.03']]\n",
      "[[18, 61, '2.91', '3.03']]\n",
      "[[18, 61, '2.91', '3.03']]\n",
      "[[32, 79, '2.91', '3.07']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Bore &Stroke\n",
    "from operator import itemgetter\n",
    "for i in range(0, len(df.stroke),1):\n",
    "    if(str(df.stroke[i]) == \"nan\"):\n",
    "        #print(i)\n",
    "        refferenceEngine = df.engineSize[i]\n",
    "        #print(refferenceEngine)\n",
    "        #finde alle die kleiner sind\n",
    "        possibleMachines = [] \n",
    "        for j in range(0, len(df),1):\n",
    "            if(df.engineSize[j]<refferenceEngine):\n",
    "                possibleMachines.append([j, df.engineSize[j], df.bore[j], df.stroke[j]])\n",
    "            else:\n",
    "                pass\n",
    "        #print(possibleMachines)\n",
    "        detectedValue=[possibleMachines[0]]# finde aus den möglichen Maschinen, die nächst kleinere\n",
    "        for j in range(0, len(possibleMachines),1):\n",
    "           \n",
    "            if(int(detectedValue[0][1]) >= int(possibleMachines[j][1])):\n",
    "                pass\n",
    "            else:\n",
    "                detectedValue = [possibleMachines[j]]\n",
    "        print(detectedValue)\n",
    "            \n",
    "        #jetzt den Update im Dataframe mit den broke & stroke von übergebenen DetectedValue (bei index = 0)\n",
    "        df.bore[i] = detectedValue[0][2]\n",
    "        df.stroke[i] = detectedValue[0][3]\n",
    "df[['bore']]=df[['bore']].astype('float64')\n",
    "df[['stroke']]=df[['stroke']].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bore.isna().any()\n",
    "df.stroke.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 131, '140', '5500']]\n",
      "[[8, 131, '140', '5500']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# HP&PRPM\n",
    "for i in range(0, len(df.horsepower),1):\n",
    "    if(str(df.horsepower[i]) == \"nan\"):\n",
    "        refferenceEngine = df.engineSize[i]\n",
    "        possibleMachines = [] \n",
    "        for j in range(0, len(df),1):\n",
    "            if(df.engineSize[j]<refferenceEngine):\n",
    "                possibleMachines.append([j, df.engineSize[j], df.horsepower[j], df.peakRpm[j]])\n",
    "            else:\n",
    "                pass\n",
    "        detectedValue=[possibleMachines[0]]\n",
    "        for j in range(0, len(possibleMachines),1): # finde aus den möglichen Maschinen, die nächst kleinere\n",
    "            if(int(detectedValue[0][1]) >= int(possibleMachines[j][1])):\n",
    "                pass\n",
    "            else:\n",
    "                detectedValue = [possibleMachines[j]]\n",
    "        print(detectedValue)\n",
    "            \n",
    "        #jetzt den Update im Dataframe mit den broke & stroke von übergebenen DetectedValue (bei index = 0)\n",
    "        df.horsepower[i] = detectedValue[0][2]\n",
    "        df.peakRpm[i] = detectedValue[0][3]\n",
    "#df.horsepower.isna().any()\n",
    "#df.peakRpm.isna().any()\n",
    "\n",
    "df[['horsepower']]=df[['horsepower']].astype('float64')\n",
    "df[['peakRpm']]=df[['peakRpm']].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OHE\n",
    "hier kann ich ein OHE verwenden"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "interim = one_hot_encoder.fit_transform(df.make.values.reshape(-1,1))\n",
    "interim = pd.DataFrame(interim.toarray(), columns=one_hot_encoder.categories_) \n",
    "df = pd.concat([df, interim], axis=1, sort=False)\n",
    "df = df.drop(['make'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfOHE=['make','fuelType','aspiration','numOfDoors','bodyStyle','driveWheels','engineLocation',\n",
    "           'engineType','numOfCylinders', 'fuelSystem']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "listOfOHE=['fuelType','aspiration']\n",
    "# bodystyle??'driveWheels',engineLocation',          'engineType','numOfCylinders', 'fuelSystem', 'numOfDoors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# show all Columns\\nfor col in df.columns: \\n    print(col)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "for feature in range(0,len(listOfOHE),1):\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    command = 'interim = one_hot_encoder.fit_transform(df.{}.values.reshape(-1,1))'.format(listOfOHE[feature])\n",
    "    exec(command)\n",
    "    interim = pd.DataFrame(interim.toarray(), columns=one_hot_encoder.categories_)\n",
    "    df = pd.concat([df, interim], axis=1, sort=False)\n",
    "    df = df.drop([listOfOHE[feature]], axis=1)\n",
    "    \n",
    "'''\n",
    "# show all Columns\n",
    "for col in df.columns: \n",
    "    print(col)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'./test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalized loss\n",
    "Ich versuche das mit einem Modell vorherzusagen, dazu muss aber die gesammelte andere Vorverarbeitung aller anderen Feature abgeschlossen sein. => das geschieht ganz zum schluss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) ergänzen von df um den Orginalindex, für die spätere rückordnung\n",
    "indexlist=list(range(0,len(df),1))\n",
    "dfIndex=pd.DataFrame(indexlist, columns=['OrginalIndex'])\n",
    "df = pd.concat([dfIndex, df], axis=1, sort=False)\n",
    "#split in die Werte die Nas(diese wollen wir durch das Modell predicten) haben und die die keine haben(mit diesen wollen wir modellieren)\n",
    "toBePredicted = []\n",
    "listForModelling = []\n",
    "for i in range(0,len(df),1):\n",
    "    #print(df.normalizedLosses[i])\n",
    "    if(str(df.normalizedLosses[i]) == \"nan\"):\n",
    "        interim = (list(df.iloc[i,]))\n",
    "        toBePredicted.append(interim)\n",
    "    else:\n",
    "        interim = (list(df.iloc[i,]))\n",
    "        listForModelling.append(interim)\n",
    "        \n",
    "titles = []\n",
    "for col in df.columns: \n",
    "    titles.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 77)\n",
      "(164, 77)\n"
     ]
    }
   ],
   "source": [
    "#Erstellen von DF spezifisch für die Anwendung modellierung bzw prediction\n",
    "DFtoBePredicted = pd.DataFrame(toBePredicted, columns = titles) \n",
    "print(DFtoBePredicted.shape)\n",
    "DFlistForModelling = pd.DataFrame(listForModelling, columns = titles) \n",
    "print(DFlistForModelling.shape) # <= auf dieses setzte ich jetzt ein Regressionsmodell an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 76)\n",
      "(164, 1)\n"
     ]
    }
   ],
   "source": [
    "# Horizontale aufteilung\n",
    "# über den Loop finde ich die Position von normalizedloss\n",
    "for i in range(0,len(DFlistForModelling),1):\n",
    "    #print(DFlistForModelling.columns[i])\n",
    "    if(str(DFlistForModelling.columns[i]) == \"normalizedLosses\"):\n",
    "        position=[i]\n",
    "        break\n",
    "        \n",
    "input_df = DFlistForModelling.drop(['normalizedLosses'], axis=1)\n",
    "print(input_df.shape)\n",
    "output_df = DFlistForModelling.iloc[:,position]\n",
    "print(output_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VertikaleAufteilung in test & Train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    input_df, \n",
    "    output_df,\n",
    "    test_size=0.2,\n",
    "    random_state = 90\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "             with_scaling=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### skallieren der Daten\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "robust_scaler_X = RobustScaler()\n",
    "robust_scaler_y = RobustScaler()\n",
    "robust_scaler_X.fit(train_X)\n",
    "robust_scaler_y.fit(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_X = robust_scaler_X.transform(train_X)\n",
    "scaled_test_X = robust_scaler_X.transform(test_X)\n",
    "scaled_train_y = robust_scaler_y.transform(train_y)\n",
    "scaled_test_y = robust_scaler_y.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lineare Regression für die imputation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linerar_regressor = LinearRegression()\n",
    "linerar_regressor.fit(scaled_train_X, scaled_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = linerar_regressor.predict(scaled_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5719562994047731"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linerar_regressor.score(scaled_test_X, scaled_test_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicht übertreiben schlecht, ich verwende nun dieses Modell um die normalized loss von dem DF vorherzusagen verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vorbereiten der 2bePredicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = DFtoBePredicted.drop(['normalizedLosses'], axis=1)\n",
    "robust_scaler_X_toBepredicted = RobustScaler()\n",
    "scaled_X_toBepredicted = robust_scaler_X.transform(prediction_df)\n",
    "prediction2 = linerar_regressor.predict(scaled_X_toBepredicted)\n",
    "rescaledPredictions = (robust_scaler_y.inverse_transform(prediction2))\n",
    "rescaledPredictionslist = []\n",
    "for i in range(0, len(rescaledPredictions),1):\n",
    "    rescaledPredictionslist.append(int(rescaledPredictions[i]))\n",
    "\n",
    "\n",
    "testlist = []\n",
    "for i in range(0,len(df),1):\n",
    "    if(str(df.normalizedLosses[i])==\"nan\"):\n",
    "        testlist.append(str(rescaledPredictionslist[0]))\n",
    "        rescaledPredictionslist.pop(0)\n",
    "    else:\n",
    "         testlist.append(df.normalizedLosses[i])\n",
    "#create datafframe final\n",
    "dfNormalizedLosses = pd.DataFrame(testlist, columns=['normalizedLosses'])\n",
    "df = df.drop(['normalizedLosses'], axis=1)\n",
    "df = pd.concat([dfNormalizedLosses, df], axis=1, sort=False)\n",
    "\n",
    "#interim = pd.DataFrame(interim.toarray(), columns=one_hot_encoder.categories_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'./FinalDF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finaler Check\n",
    "hier schau ich lediglich ob iwo noch ein NA vorhanden ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28a042340b8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
