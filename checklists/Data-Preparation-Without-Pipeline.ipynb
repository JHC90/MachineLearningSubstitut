{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "Dieses Notebook, dient lediglich zu Entwicklung von Vorverarbeitungsstrategien. Daher wird auf jedes Feature grob eingegangen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliiotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelList=['symboling','normalizedLosses','make','fuelType','aspiration','numOfDoors','bodyStyle','driveWheels','engineLocation',\n",
    "           'wheelBase','length','width','height','curbWeight','engineType','numOfCylinders','engineSize','fuelSystem','bore',\n",
    "           'stroke','compressionRatio','horsepower','peakRpm','cityMpg','highwayMpg','price']\n",
    "df = pd.read_csv('../data/data_car-CopyForEDA.csv',delimiter=',',encoding='utf-8', names=labelList)\n",
    "df = df.replace(\"?\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## symboling\n",
    "laut First-Touch kein Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## price\n",
    "NAs werden duch den Druchschnittswert der Marke ausgewählt\n",
    "Der Datentyp wird in int gewandelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#df.price.isna().any()# > sind noch nas\n",
    "df[['price']]=df[['price']].astype('float64')\n",
    "for i in range(0, len(df.price),1):\n",
    "    if(str(df.price[i]) == \"nan\"):\n",
    "        nanmake = (df.make[i])\n",
    "        subSetNanMake=df[df['make'] == nanmake]\n",
    "        subSetNanMake = subSetNanMake.price.dropna()\n",
    "        medianPerMake = subSetNanMake.median(axis = 0, skipna = True)\n",
    "        df.price[i] = medianPerMake\n",
    "#df.price.isna().any() => keine Nas Mehr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numOfDoors\n",
    "nas werden durch den Modus ersetzt der entsprechenden Wagenklasse(bodyStyle). ich geh davon aus dass eine wagenklasse meist die gleiche Türenanzhal hat => ich setzt den Modus dazu rein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two' 'four' nan]\n"
     ]
    }
   ],
   "source": [
    "print(df.numOfDoors.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#df.numOfDoors.isna().any() #=> noch nas\n",
    "for i in range(0, len(df.numOfDoors),1):\n",
    "    if(str(df.numOfDoors[i]) == \"nan\"):\n",
    "        nanBodyStyle = (df.bodyStyle[i])\n",
    "        subSetNanBody=df[df['bodyStyle'] == nanBodyStyle]\n",
    "        subSetNanBody = subSetNanBody.numOfDoors.dropna()\n",
    "        modusNumOfDoors = subSetNanBody.mode().iloc[0]\n",
    "        #print(modusNumOfDoors)\n",
    "        df.numOfDoors[i] = modusNumOfDoors\n",
    "#df.numOfDoors.isna().any() # => keine Nas Mehr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der nachfolgede Teil zu numOfDoors ist aufgekommen, da im OHE ein außergewöhnlicher wert erschienen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two' 'four']\n"
     ]
    }
   ],
   "source": [
    "print(df.numOfDoors.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bore & Stroke & horse power & Peakrpm\n",
    "Das sind die Parameter, die den Hubraum(engine-Size) beschreiben. Nach ewig langer recherche errechne ich aber auch  bei Datensätzen bei welchen ich sowohl bore, stroke, horsepower & PRPM als auch engine habnciht den richtigen Hubrubraum. Somit geh ich anders vor.\n",
    "    1) finde Nonvalues in den bereichen (glück = bei Stroke&bore als auch bei HP&PRPM sind es jeweils die gleichen Datensätze)\n",
    "    2) wähle von nonvalue die Enigine size\n",
    "    3) finde die nächst kleinere Engine size\n",
    "    4) impute von den nächst kleineren die bore & Storke values dem leeren Feld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bore.isna().any()\n",
    "df.stroke.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 61, '2.91', '3.03']]\n",
      "[[18, 61, '2.91', '3.03']]\n",
      "[[18, 61, '2.91', '3.03']]\n",
      "[[32, 79, '2.91', '3.07']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Bore &Stroke\n",
    "from operator import itemgetter\n",
    "for i in range(0, len(df.stroke),1):\n",
    "    if(str(df.stroke[i]) == \"nan\"):\n",
    "        #print(i)\n",
    "        refferenceEngine = df.engineSize[i]\n",
    "        #print(refferenceEngine)\n",
    "        #finde alle die kleiner sind\n",
    "        possibleMachines = [] \n",
    "        for j in range(0, len(df),1):\n",
    "            if(df.engineSize[j]<refferenceEngine):\n",
    "                possibleMachines.append([j, df.engineSize[j], df.bore[j], df.stroke[j]])\n",
    "            else:\n",
    "                pass\n",
    "        #print(possibleMachines)\n",
    "        detectedValue=[possibleMachines[0]]# finde aus den möglichen Maschinen, die nächst kleinere\n",
    "        for j in range(0, len(possibleMachines),1):\n",
    "           \n",
    "            if(int(detectedValue[0][1]) >= int(possibleMachines[j][1])):\n",
    "                pass\n",
    "            else:\n",
    "                detectedValue = [possibleMachines[j]]\n",
    "        print(detectedValue)\n",
    "            \n",
    "        #jetzt den Update im Dataframe mit den broke & stroke von übergebenen DetectedValue (bei index = 0)\n",
    "        df.bore[i] = detectedValue[0][2]\n",
    "        df.stroke[i] = detectedValue[0][3]\n",
    "df[['bore']]=df[['bore']].astype('float64')\n",
    "df[['stroke']]=df[['stroke']].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bore.isna().any()\n",
    "df.stroke.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\1810837475\\.conda\\envs\\Kompensationsarbeit\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 131, '140', '5500']]\n",
      "[[8, 131, '140', '5500']]\n"
     ]
    }
   ],
   "source": [
    "# HP&PRPM\n",
    "for i in range(0, len(df.horsepower),1):\n",
    "    if(str(df.horsepower[i]) == \"nan\"):\n",
    "        refferenceEngine = df.engineSize[i]\n",
    "        possibleMachines = [] \n",
    "        for j in range(0, len(df),1):\n",
    "            if(df.engineSize[j]<refferenceEngine):\n",
    "                possibleMachines.append([j, df.engineSize[j], df.horsepower[j], df.peakRpm[j]])\n",
    "            else:\n",
    "                pass\n",
    "        detectedValue=[possibleMachines[0]]\n",
    "        for j in range(0, len(possibleMachines),1): # finde aus den möglichen Maschinen, die nächst kleinere\n",
    "            if(int(detectedValue[0][1]) >= int(possibleMachines[j][1])):\n",
    "                pass\n",
    "            else:\n",
    "                detectedValue = [possibleMachines[j]]\n",
    "        print(detectedValue)\n",
    "            \n",
    "        #jetzt den Update im Dataframe mit den broke & stroke von übergebenen DetectedValue (bei index = 0)\n",
    "        df.horsepower[i] = detectedValue[0][2]\n",
    "        df.peakRpm[i] = detectedValue[0][3]\n",
    "#df.horsepower.isna().any()\n",
    "#df.peakRpm.isna().any()\n",
    "\n",
    "df[['horsepower']]=df[['horsepower']].astype('float64')\n",
    "df[['peakRpm']]=df[['peakRpm']].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OHE\n",
    "hier kann ich ein OHE verwenden"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "interim = one_hot_encoder.fit_transform(df.make.values.reshape(-1,1))\n",
    "interim = pd.DataFrame(interim.toarray(), columns=one_hot_encoder.categories_) \n",
    "df = pd.concat([df, interim], axis=1, sort=False)\n",
    "df = df.drop(['make'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfOHE=['make','fuelType','aspiration','numOfDoors','bodyStyle','driveWheels','engineLocation',\n",
    "           'engineType','numOfCylinders', 'fuelSystem']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "listOfOHE=['fuelType','aspiration']\n",
    "# bodystyle??'driveWheels',engineLocation',          'engineType','numOfCylinders', 'fuelSystem', 'numOfDoors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# show all Columns\\nfor col in df.columns: \\n    print(col)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "for feature in range(0,len(listOfOHE),1):\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    command = 'interim = one_hot_encoder.fit_transform(df.{}.values.reshape(-1,1))'.format(listOfOHE[feature])\n",
    "    exec(command)\n",
    "    interim = pd.DataFrame(interim.toarray(), columns=one_hot_encoder.categories_)\n",
    "    df = pd.concat([df, interim], axis=1, sort=False)\n",
    "    df = df.drop([listOfOHE[feature]], axis=1)\n",
    "    \n",
    "'''\n",
    "# show all Columns\n",
    "for col in df.columns: \n",
    "    print(col)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalized loss\n",
    "Ich versuche das mit einem Modell vorherzusagen, dazu muss aber die gesammelte andere Vorverarbeitung aller anderen Feature abgeschlossen sein. => das geschieht ganz zum schluss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) ergänzen von df um den Orginalindex, für die spätere rückordnung\n",
    "indexlist=list(range(0,len(df),1))\n",
    "dfIndex=pd.DataFrame(indexlist, columns=['OrginalIndex'])\n",
    "df = pd.concat([dfIndex, df], axis=1, sort=False)\n",
    "#split in die Werte die Nas(diese wollen wir durch das Modell predicten) haben und die die keine haben(mit diesen wollen wir modellieren)\n",
    "toBePredicted = []\n",
    "listForModelling = []\n",
    "for i in range(0,len(df),1):\n",
    "    #print(df.normalizedLosses[i])\n",
    "    if(str(df.normalizedLosses[i]) == \"nan\"):\n",
    "        interim = (list(df.iloc[i,]))\n",
    "        toBePredicted.append(interim)\n",
    "    else:\n",
    "        interim = (list(df.iloc[i,]))\n",
    "        listForModelling.append(interim)\n",
    "        \n",
    "titles = []\n",
    "for col in df.columns: \n",
    "    titles.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 77)\n",
      "(164, 77)\n"
     ]
    }
   ],
   "source": [
    "#Erstellen von DF spezifisch für die Anwendung modellierung bzw prediction\n",
    "DFtoBePredicted = pd.DataFrame(toBePredicted, columns = titles) \n",
    "print(DFtoBePredicted.shape)\n",
    "DFlistForModelling = pd.DataFrame(listForModelling, columns = titles) \n",
    "print(DFlistForModelling.shape) # <= auf dieses setzte ich jetzt ein Regressionsmodell an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 76)\n",
      "(164, 1)\n"
     ]
    }
   ],
   "source": [
    "# Horizontale aufteilung\n",
    "# über den Loop finde ich die Position von normalizedloss\n",
    "for i in range(0,len(DFlistForModelling),1):\n",
    "    #print(DFlistForModelling.columns[i])\n",
    "    if(str(DFlistForModelling.columns[i]) == \"normalizedLosses\"):\n",
    "        position=[i]\n",
    "        break\n",
    "        \n",
    "input_df = DFlistForModelling.drop(['normalizedLosses'], axis=1)\n",
    "print(input_df.shape)\n",
    "output_df = DFlistForModelling.iloc[:,position]\n",
    "print(output_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VertikaleAufteilung in test & Train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    input_df, \n",
    "    output_df,\n",
    "    test_size=0.2,\n",
    "    random_state = 90\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "             with_scaling=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### skallieren der Daten\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "robust_scaler_X = RobustScaler()\n",
    "robust_scaler_y = RobustScaler()\n",
    "robust_scaler_X.fit(train_X)\n",
    "robust_scaler_y.fit(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_X = robust_scaler_X.transform(train_X)\n",
    "scaled_test_X = robust_scaler_X.transform(test_X)\n",
    "scaled_train_y = robust_scaler_y.transform(train_y)\n",
    "scaled_test_y = robust_scaler_y.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lineare Regression für die imputation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linerar_regressor = LinearRegression()\n",
    "linerar_regressor.fit(scaled_train_X, scaled_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = linerar_regressor.predict(scaled_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5719562994047731"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linerar_regressor.score(scaled_test_X, scaled_test_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicht übertreiben schlecht, ich verwende nun dieses Modell um die normalized loss von dem DF vorherzusagen verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vorbereiten der 2bePredicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = DFtoBePredicted.drop(['normalizedLosses'], axis=1)\n",
    "robust_scaler_X_toBepredicted = RobustScaler()\n",
    "scaled_X_toBepredicted = robust_scaler_X.transform(prediction_df)\n",
    "prediction2 = linerar_regressor.predict(scaled_X_toBepredicted)\n",
    "rescaledPredictions = (robust_scaler_y.inverse_transform(prediction2))\n",
    "rescaledPredictionslist = []\n",
    "for i in range(0, len(rescaledPredictions),1):\n",
    "    rescaledPredictionslist.append(int(rescaledPredictions[i]))\n",
    "\n",
    "\n",
    "testlist = []\n",
    "for i in range(0,len(df),1):\n",
    "    if(str(df.normalizedLosses[i])==\"nan\"):\n",
    "        testlist.append(str(rescaledPredictionslist[0]))\n",
    "        rescaledPredictionslist.pop(0)\n",
    "    else:\n",
    "         testlist.append(df.normalizedLosses[i])\n",
    "#create datafframe final\n",
    "dfNormalizedLosses = pd.DataFrame(testlist, columns=['normalizedLosses'])\n",
    "df = df.drop(['normalizedLosses', 'OrginalIndex'], axis=1)\n",
    "df = pd.concat([dfNormalizedLosses, df], axis=1, sort=False)\n",
    "\n",
    "#interim = pd.DataFrame(interim.toarray(), columns=one_hot_encoder.categories_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'./Final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finaler Check\n",
    "hier schau ich lediglich ob iwo noch ein NA vorhanden ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x298fe9991d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
